# 记忆系统构想记录

本文档用于记录关于记忆系统设计的原始表述和构想。

---

## 0. 系统定位与边界

### 0.1 智能体隔离原则

**每个智能体拥有独立的记忆系统实例**：
- 记忆系统不在智能体之间共享
- 每个智能体的记忆网络完全独立演化
- 智能体A的记忆遗忘不会影响智能体B
- 隔离确保记忆与特定智能体的经历绑定

### 0.2 执行模型

**线性业务 + 异步内部队列**：

| 层级 | 执行模型 | 说明 |
|------|----------|------|
| **业务逻辑层** | 线性执行 | 智能体业务代码按顺序执行，不并发调用记忆 |
| **记忆系统层** | 异步队列 | 记忆系统内部维护任务队列，独立调度处理 |

**为什么这样设计**：
- 业务层线性：保证智能体思维过程的因果一致性
- 记忆层异步：压缩、检索等操作耗时，不阻塞主线程
- 队列隔离：记忆系统自主管理内部状态，不受前端业务节奏影响

### 0.3 持久化与生命周期

**数据持久化**：
- 记忆数据持久化存储到硬盘
- 每个智能体拥有独立的数据库文件夹，以智能体ID命名
- 文件夹完全隔离，一个智能体的数据不影响其他智能体

**生命周期**：
- **初始化**：尝试从数据库文件夹加载已有数据；如文件夹不存在，则创建新的空数据库
- **运行**：数据在内存中操作，适时同步到硬盘
- **关闭**：确保数据写入硬盘，关闭数据库连接

---

## 1. 系统参数

记忆系统的可调节参数：

| 参数名 | 概念说明 | 典型值 |
|--------|----------|--------|
| **focus_limit** | 关注点数量上限 | 5 |
| **decay_rate** | 关联衰减速率（每次压缩） | 0.97 |
| **link_initial_strength** | 新建关联初始强度 | 0.5 |
| **delete_threshold** | 删除阈值（字符数） | 5 |
| **link_break_threshold** | 关联断裂阈值 | 0.01 |
| **time_slice** | 压缩时间片长度（毫秒） | 30000 |
| **max_retries** | 小模型压缩失败重试次数 | 15 |
| **default_search_depth** | 默认搜索深度 | 2 |

这些参数影响遗忘速度、保护范围、系统性能等。

---

## 2. 核心观点

### 2.1 记忆的本质

记忆是**记忆节点的超链接网络**。

- 每个节点包含内容以及与其他记忆节点的关联关系
- 网络结构是记忆的本质形态，节点通过超链接相互连接
- 记忆的价值不在于孤立存储，而在于网络中的连接关系

### 2.2 与现有方案的区别

| 特性 | 本方案 | 向量数据库+RAG | MemGPT | 传统记忆系统 |
|------|--------|----------------|--------|--------------|
| **核心结构** | 超链接网络（节点+关联） | 孤立向量 | 分层存储 | 键值对/列表 |
| **检索方式** | BFS从关注点向外搜索 | 全局相似度匹配 | 固定窗口+分层检索 | 精确匹配/最近访问 |
| **遗忘机制** | 渐进压缩+关联断裂 | 无遗忘，永久存储 | 压缩归档或删除 | TTL过期/固定容量淘汰 |
| **保护机制** | 重要性（关联强度之和） | 无 | 核心上下文固定保留 | 无 |
| **动态保护** | 关注点机制（LRU 5个） | 无 | 无 | 无 |
| **时间度量** | 压缩循环次数+扫描次数 | 无时间概念 | 无时间概念 | 物理时间/TTL |
| **关联衰减** | 每次压缩衰减 | 无关联 | 无关联 | 无关联 |
| **搜索起点** | 当前关注点 | 全库 | 最近上下文 | 全库/固定范围 |
| **压缩方式** | 语义压缩（小模型） | 无压缩 | 摘要压缩 | 删除/截断 |
| **长期记忆** | 扫描次数累积（访问少=保留久） | 无区分 | 外部存储 | 备份机制 |
| **智能体隔离** | 每个智能体独立实例 | 通常共享 | 通常共享 | 通常共享 |
| **执行模型** | 线性业务+内部异步队列 | 同步调用 | 同步/异步 | 同步调用 |

#### 关键差异说明

**1. 网络结构 vs 孤立存储**
- 本方案：记忆节点通过关联形成网络，检索时沿着关联传播
- 向量库：每个记忆是独立向量，检索时计算与查询的相似度
- 优势：网络结构模拟人类记忆的联想特性，相关记忆自然聚集

**2. 渐进压缩 vs 二元删除**
- 本方案：内容随重要性降低而逐步压缩，直到字数<10才删除
- 传统方案：要么保留完整内容，要么直接删除
- 优势：避免信息突然丢失，给记忆"淡出"的过程

**3. 关注点动态保护**
- 本方案：当前讨论相关的记忆自动成为关注点，不受压缩
- 其他方案：缺乏对"当前相关"的动态识别和保护
- 优势：确保对话连贯性，不会被意外遗忘打断

**4. 扫描次数=长期记忆**
- 本方案：被频繁扫描的记忆扫描次数增加，后续被扫描间隔变长
- 其他方案：要么固定保留，要么按时间淘汰
- 优势：真正常用的记忆形成"长期记忆"，不常用的逐渐被压缩

**5. 重要性驱动 vs 相似度驱动**
- 本方案：重要性=关联强度之和，决定是否压缩
- RAG方案：相似度=向量距离，决定是否召回
- 本质区别：重要性是节点的"保护力"，相似度是查询的"匹配度"

**6. 时间作为过程而非参数**
- 本方案：时间不参与计算，时间流逝体现为"进行了多少次压缩"
- 其他方案：通常使用物理时间（TTL、时间戳）
- 优势：遗忘速度与系统活跃度相关，而非真实时间

**7. 智能体隔离 vs 共享存储**
- 本方案：每个智能体拥有独立的记忆系统实例，数据完全隔离
- 其他方案：通常多个智能体共享同一向量库或数据库
- 优势：记忆与个体经历绑定，遗忘也是个体化的

**8. 异步队列执行模型**
- 本方案：业务层线性调用，记忆系统内部异步队列处理
- 其他方案：通常同步调用，直接返回结果
- 优势：耗时操作（压缩、检索）不阻塞业务逻辑，同时保证状态一致性

---

## 2. 节点结构

每个记忆节点包含以下要素：

| 要素 | 说明 | 变化趋势 |
|------|------|----------|
| **内容** | 记忆的完整内容 | 随重要性逐步缩减 |
| **短语** | 内容的简短概括 | 随内容缩减而减少 |
| **关键词** | 用于关联和检索的标签 | 随内容缩减而减少 |
| **时间** | 记忆创建时间 | 元数据，仅记录 |
| **扫描次数** | 被压缩扫描的次数 | 每次扫描+1 |

### 3.1 内容的语义压缩

节点内容持续经历压缩：

```
完整内容
    │
    ▼ 0 < 重要性 < 1
内容按比例保留（目标字数 = min(重要性,1) × 原文）
    │
    ▼ 重要性降低（关联衰减）
保留字数减少
    │
    ▼ 重要性 = 0 或 字数 < 10
遗忘（节点从网络中移除）
```

**关键机制**：
- 压缩是**连续的、渐进的**，而非离散的步骤
- 重要性由数学公式决定，而非if-else判断
- 重要性：**所有关联强度之和，[0, ∞)**
  - 重要性 = 0：保留0%（直接删除节点/遗忘）
  - 0 < 重要性 < 1：保留 `重要性` 比例的内容
  - 重要性 ≥ 1：保留100%（不压缩，受到保护）

---

## 3. 重要性公式

### 4.1 核心公式

重要性由以下因素**连续计算**得出：

```
重要性 = 所有关联强度之和
```

**输入变量**：

| 变量 | 符号 | 说明 | 取值范围 |
|------|------|------|----------|
| 关联强度列表 | [s₁, s₂, ...] | 该节点所有关联的强度值列表 | 每个 sᵢ ∈ [0, 1] |

**计算方式**：
```
重要性 = Σ sᵢ  (所有关联强度之和)
```

**说明**：
- 当前为简化定义，直接求和
- 取值范围：[0, ∞)，无上界
- 后续可能添加激活函数映射到 [0, 1]

**时间的作用**：
- 时间是**元数据**，仅记录记忆创建的时间点
- **不参与重要性计算**
- 时间流逝的效果通过以下机制自然体现：
  - 大批节点持续压缩 → 内容退化 → 关联断裂
  - 节点被遗忘 → 其关联的其他节点失去支撑 → 连锁遗忘
  - 网络整体的演化本身就蕴含了时间流逝

**公式特性**：
- 所有关联强度**同时参与**计算
- 重要性与连接强度**正相关**（关联越多越强，越不容易被遗忘）
- 取值范围：[0, ∞)

### 4.2 压缩的必然性：过程即时间

**核心洞察**：

只要 **0 < 重要性 < 1**，节点就会被压缩。重要性越低，保留的内容越少。

```
重要性 = 0.5
    │
    ▼ 每次系统循环
保留50%内容
    │
    ▼ 关联强度衰减 → 重要性降低
保留内容比例下降
    │
    ▼ 持续进行
重要性 → 0（关联全部断裂）→ 遗忘
```

**这就是时间的力量**：

- 不需要显式的"时间变量"
- 不需要计算"经过了多少秒"
- **持续的压缩过程本身就是时间的度量**
- 每个压缩循环 = 一个时间单位

**阻止压缩（保留全部内容）的唯一方式**：

重要性 ≥ 1

这需要：
- 至少一个强度为1的关联（如与关注点关联）

在实际情况中，这些条件难以持续满足，因此**遗忘是必然的**。

### 4.3 动态平衡与必然遗忘

**压缩的必然性**：

只要 **0 < 重要性 < 1**，压缩就进行；每次压缩关联强度衰减，重要性降低，最终重要性=0时删除节点（遗忘）。

新建立的关联可以暂时提升重要性，但随着时间推移（多次压缩），遗忘是必然的。

这是一个**动态平衡系统**，新输入可以延缓但无法阻止遗忘。

### 4.4 遗忘条件

```
重要性 = 0  →  节点被遗忘（从网络中移除）
```

或（可选）：

```
所有关联强度 = 0  →  节点孤立 → 遗忘
```

---

## 4. 关联关系

节点之间的连接包含：

| 属性 | 说明 | 变化趋势 |
|------|------|----------|
| **强度** | 连接的紧密程度 | 随时间自然衰减 |
| **关系名称** | 关联的语义类型 | 随内容压缩可能丢失 |

### 5.1 关联强度的动态变化

- 新建立时：初始强度 = `link_initial_strength`（默认 0.5）
- 时间推移：自然衰减（每次压缩时乘以 decay_rate）

#### 关联强度衰减机制

**关联衰减速率**（`decay_rate`）：每次压缩时的强度衰减系数

| 属性 | 说明 |
|------|------|
| 取值范围 | (0, 1] |
| 典型值 | 0.95 ~ 0.99（每次压缩衰减1%~5%） |
| 计算方式 | 新强度 = 旧强度 × decay_rate |

**节点删除时机**：重要性 = 0 时，直接删除节点

```
压缩节点
    │
    ▼ 计算重要性 = Σ关联强度
    │
    ├─ 重要性 ≥ 1 → 受保护，跳过
    │
    ├─ 0 < 重要性 < 1 → 执行压缩
    │
    └─ 重要性 = 0 → 直接删除节点（不处理关联）
```

**关联的懒删除与"记得曾经记得"**：
- 节点删除时**不主动清理**指向它的关联
- 悬空关联（目标节点已不存在的关系）表达了**"曾经知道但已遗忘"**的概念
- 智能体可以通过感知悬空关联，意识到自己曾经记得某事，但现在忘记了
- 这种设计赋予了遗忘以**可感知性**，而非彻底的虚无

### 5.2 关联的形成机制（概念视角）

记忆系统中的**关联不需要主动声明**，而是通过记忆的自然积累过程**自发形成**。

#### 关联的自发形成

**1. 时间顺序关联（蕴含形成）**
```
用户讨论话题A → 创建节点A（成为关注点）
    │
用户继续讨论话题B → 创建节点B
    │
    ▼ 节点B与当前关注点（节点A）建立关联
    
时间链条自然形成：A ↔ B ↔ C ↔ ...
```

时间顺序不需要显式的时间戳记录，而是通过**与当前关注点的关联**自然蕴含。新记忆与当前活跃的记忆建立强关联，形成时间流。

**2. 语义连贯关联（切割形成）**
```
长文本输入
    │
语义切割 → [小段1, 小段2, 小段3]
    │
    ▼ 段间关联
小段1 ↔ 小段2 ↔ 小段3（强度0.5）
```

同一来源的多个记忆片段之间自动建立关联，保持原始文本的语义连贯性。

**3. 隐含关联（相似形成）**
```
用户今天说："我喜欢吃苹果"
    ↓ 创建节点A

用户明天说："我喜欢吃苹果"
    ↓ 创建节点B（内容相似的副本）
    
节点A和节点B都关联到"苹果"这个关注点
    ↓
通过共享关注点，两个节点形成隐含关联
```

当用户多次讨论相似内容时，系统创建**内容相似的节点副本**。这些副本通过**共享的关注点**自然形成关联网络。旧副本被遗忘后，新副本仍然保留，确保重要信息不会因为单次遗忘而丢失。

#### 副本独立性原则

每个记忆节点都是**独立的实体**：
- 节点A和节点B即使有相似内容，也是两个独立的记忆
- 节点A被遗忘，不影响节点B的存在
- 这种"冗余"设计确保重要记忆的存活率

#### 关联与检索的关系

关联不是为存储而存在，而是为检索而存在：
- **存储时**：关联自然形成，无需人工干预
- **检索时**：通过关联网络（BFS）发现相关记忆
- 关联强度决定检索时的路径优先级

### 5.3 节点的遗忘与关联的清理

**遗忘条件**：
```
重要性 = 0  →  直接删除节点（无需处理关联）
```

**关联的懒删除机制**：

```
节点A → 关联 → [节点B（已删除）]
    │
    ▼ 从A出发遍历关联时
    │
    ▼ 发现节点B不存在
    │
    ▼ 自动删除A到B的关联
```

**为什么采用懒删除？**

| 方案 | 问题 | 本方案（懒删除）|
|------|------|----------------|
| 级联删除 | 删除节点时需遍历所有关联，O(n)复杂度 | 删除节点时直接删除，O(1)复杂度 |
| 预清理 | 增加压缩流程的复杂度和耗时 | 压缩流程只处理节点，不处理关联 |
| 引用计数 | 需要维护计数器，增加写入开销 | 无额外写入开销 |

**"记得曾经记得"——悬空关联的语义价值**：

悬空关联（dangling link）不是需要清理的垃圾，而是具有独立语义的记忆痕迹：

```
节点A → 关联 → [节点B（已删除）]
    │
    └─ 表达了：A曾经与B有关联，但B已被遗忘
```

这种结构使智能体能够：
1. **感知遗忘的存在**：意识到自己曾经知道某事
2. **定位遗忘的位置**：知道在哪个领域失去了记忆
3. **理解自身的知识边界**：明确区分"从未知道"和"曾经知道但忘了"

**关联消失的唯一条件**：

关联只能从**源端**消失，不能从**目标端**消失：

```
源节点被删除          关联强度衰减至断裂阈值
        │                       │
        ▼                       ▼
   关联自然消失            关联断裂消失
```

目标节点的删除不会导致关联消失，只会使其成为悬空关联，保留"曾经记得"的语义。

**关联与压缩的关系**：
- 关联强度衰减 → 重要性降低 → 节点更容易被遗忘
- 节点删除后，指向它的关联变成"悬垂关联"，保留"曾经知道"的痕迹
- 悬垂关联不会被自动清理，只能通过源节点删除或自然衰减消失

---

## 5. 数学化设计原则

### 6.1 连续而非离散

| 离散设计（避免） | 连续设计（采用） |
|----------------|----------------|
| if-else判断 | 数学函数计算 |
| "是/否"遗忘 | 重要性从高到低渐变 |
| "强/中/弱"关联等级 | 强度连续值 [0,1] |
| 阶段性压缩 | 连续比例缩减 |

### 6.2 多因素同时作用

所有影响因素**同时输入公式**，无优先级顺序：

```
最终状态 = Formula(因素A, 因素B, 因素C, ...)
```

而非：

```
if (因素A) {
    if (因素B) {
        ...
    }
}
```

### 6.3 需要确定的具体公式

以下公式需要明确定义：

1. **重要性公式**（核心）：
   ```
   重要性 = Σ sᵢ
   ```
   已确定：
   - 函数形式：所有关联强度之和
   - 取值范围：[0, ∞)
   - 后续可能添加激活函数映射到 [0, 1]

2. **关联强度演化**：
   ```
   sᵢ(t+1) = sᵢ(t) × decay_rate
   ```
   已确定：
   - 新关联初始强度：`link_initial_strength` = 0.5
   - 衰减机制：每次压缩时乘以 `decay_rate`

---

## 6. 记忆检索接口

### 7.1 回忆函数

智能体主动获取记忆内容的接口。

**函数签名**：
```typescript
function recall(
    keywords: string[],      // 关键词列表
    relations: string[],     // 关系列表
    depth: number            // 搜索深度（层数）
): Promise<string>
```

**参数说明**：

| 参数 | 类型 | 必填 | 建议值 | 说明 |
|------|------|------|--------|------|
| `keywords` | `string[]` | 是 | - | 用于匹配记忆节点内容的关键词 |
| `relations` | `string[]` | 是 | - | 用于筛选关联类型的关系名称，空数组表示不筛选 |
| `depth` | `number` | 是 | 2 | 从关注点开始的搜索深度（层数） |

**搜索深度说明**：
| 深度值 | 适用场景 |
|--------|----------|
| 2 | 标准值，日常思考使用 |
| > 2 | 复杂问题思考，扩大搜索范围 |

**返回值**：
- 类型：`Promise<string>`
- 格式：多个记忆内容以分隔符间隔的纯文本字符串
- **不包含**：节点ID、匹配度、距离、深度等技术细节
- **目标**：记忆形态对调用者透明，完全语义化呈现

**返回格式示例**：
```
[记忆] 昨天讨论了用户系统的登录模块设计，决定采用JWT方案。
---
[记忆] 前端组提到需要支持第三方登录，这个需求优先级待定。
---
[记忆] 架构评审时强调了安全性，建议使用短时效token。
```

分隔符（`---`）仅用于区分不同的记忆点，不包含任何结构化信息。

**设计原则：语义透明性**

记忆系统的内部结构（节点、关联、网络）对上层完全隐藏。大模型看到的只是：
- 一段段相关的文本记忆
- 以简洁分隔符区分
- 无需解析任何元数据

这种设计使得大模型可以像理解自然语言一样理解记忆，无需额外的适配逻辑。

**异步说明**：
- `recall()` 是异步函数，调用后立即返回 Promise
- 请求进入记忆系统内部任务队列，串行处理
- 搜索可能耗时较长（尤其深度较大时），但不阻塞业务逻辑
- 队列机制保证即使业务层并发调用，记忆操作也按顺序执行
- 具体任务队列实现在技术文档中讨论

**使用示例**：
```typescript
// 标准深度（日常思考）
const memory = await recall(
    ["项目", "进度"],
    ["同事", "负责"],
    2
);

// 扩大搜索范围（复杂问题）
const deepMemory = await recall(
    ["架构", "设计"],
    [],
    4
);
```

**搜索策略**：
- **算法**：广度优先搜索（BFS）
- **起点**：当前关注点
- **范围**：从关注点向外扩展 `depth` 层
- **匹配**：在搜索范围内匹配 `keywords` 和 `relations`

**注意**：
- `recall()` 只读取记忆，**不更新关注点**
- 关注点只在 `remember()` 时从聊天记录中更新

---

## 8. 关注点机制

关注是一种保护机制，确保当前讨论相关的记忆不被压缩。

### 8.1 核心概念

**关注点**：被智能体主动标记为"正在关注"的记忆节点。

| 属性 | 说明 |
|------|------|
| 数量上限 | `focus_limit`（见系统参数） |
| 排序依据 | 最后想到的时间（LRU） |
| 保护效果 | 不被压缩、关联强度固定为1 |

### 8.2 关注点的行为

**被关注的节点**：
```
压缩时跳过该节点
关联强度锁定为1（不随衰减计算）
```

**取消关注后**：
```
内容：保持当前状态（不恢复）
关联强度：保持当前值（不再锁定为1）
后续：正常参与压缩、正常衰减
```

### 8.3 关注点的来源

**关注点由聊天记录中的关键实体得出**。

当智能体调用 `remember(messages)` 时：
```
语义切割后的记忆节点
    │
    ▼ 提取关键实体（名词、代词等）
    │   示例："项目"、"用户系统"、"他"
    │
    ▼ 这些关键实体成为关注点
```

**说明**：
- 关注点在**建立记忆时**从内容中提取
- 不是回忆时产生，而是记忆时确定
- 这确保了关注点与智能体正在讨论的内容同步

### 8.4 关注点的更新机制

```
智能体调用 remember(messages)
    │
    ▼ 语义切割生成记忆节点
    │
    ▼ 提取关键实体作为候选关注点
    │
    ├─ 已存在的关注点 → 移到最新位置（LRU更新）
    │
    └─ 新关注点
        │
        ├─ 数量 < 5 → 直接添加
        │
        └─ 数量 = 5 → 淘汰最老的，添加新的
```

**淘汰策略**：LRU（Least Recently Used）
- 按照"最后提及的时间"排序
- 新的记忆提及某实体时，该实体成为最新关注点
- 长时间未被提及的关注点被淘汰

---

## 8. 记忆写入接口

### 8.1 remember 函数

智能体将聊天记录存入记忆系统的接口。

**函数签名**：
```typescript
function remember(
    messages: Message[]       // 与大模型通信的聊天记录
): void
```

**参数说明**：

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `messages` | `Message[]` | 是 | 与大模型通信的聊天记录数组 |

**Message 结构**：
```typescript
interface Message {
    role: 'user' | 'assistant' | 'system';  // 消息发送者角色
    content: string;                         // 消息内容
    timestamp?: number;                      // 消息时间戳（可选）
}
```

**处理流程**：
```
智能体调用 remember(messages)
    │
    ▼ 立即返回 Promise（不阻塞）
    │
    ▼ 将任务加入内部队列
    │   任务类型：MEMORY_CREATE
    │   任务数据：messages
    │
    ▼ 队列处理器（串行执行）
        │
        ▼ 调用小模型语义切割
        │   输入：原始聊天记录
        │   输出：segments[]（文本片段）
        │
        ▼ 对每个segment调用小模型提取phrase和keywords
        │
        ▼ 调用 store(segments, phrases, keywords)
            │
            ▼ 创建节点/建立关联
                ├─► 与当前所有关注点建立关联
                │       强度 = 1.0（固定不衰减）
                │       关系名称 = 小模型语义分析结果
                │       （示例："属于"、"关于"、"涉及"）
                │
                └─► 同一切割来源的节点之间：双向关联
                        强度 = 0.5
                        关系名称 = "上文"/"下文"
```

**关联规则**：
- **新节点与关注点关联**：
  - 强度固定为1.0，不衰减（受关注点保护）
  - 关系名称由小模型语义分析确定，描述节点与关注点的语义关系
- **切割节点间关联**：
  - 强度0.5，正常衰减，表示语义连贯性
  - 关系名称：前向为"上文"，后向为"下文"
  - 示例：节点A → "下文" → 节点B，节点B → "上文" → 节点A
- **关注点之间**：
  - 不自动建立特殊关联，遵循普通节点的关联规则

**调用说明**：
- `remember()` 是同步函数，无返回值
- 仅将任务加入队列，不等待处理完成
- 调用后立即返回，不阻塞业务逻辑
- 队列处理器后台串行处理所有记忆操作，保证内部状态一致性

---

## 9. 记忆的建立（外部触发）

### 9.1 触发机制（外部系统）

> **注意**：记忆系统本身不决定何时建立记忆。
> 
> **触发判断由大模型调度系统执行**：
> - 监控上下文长度
> - 当达到配置阈值（如最大上下文长度的80%）时
> - 将超出部分提交给记忆系统处理

**系统启动状态**：
- 记忆系统启动时**没有节点**，网络为空
- 不预置任何初始节点、示例数据或系统节点
- 所有节点均来自外部系统后续传入的聊天记录

**建议配置参数**：
| 参数 | 说明 | 建议值 |
|------|------|--------|
| `context_threshold_ratio` | 上下文阈值比例 | 80% |
| `context_max_tokens` | 最大上下文Token数 | 配置文件指定 |

### 9.2 语义切割

**步骤**：外部系统提交的记忆内容，首先经过小模型的语义切割。

```
原始长文本
    │
    ▼ 调用小模型语义切割
    │   任务：将长文本切分为语义完整的小段
    │   
    ▼ 示例：
    │   输入："我今天去了公园，看到了很多花。然后去了图书馆。"
    │   输出：["我今天去了公园，看到了很多花。", "然后去了图书馆。"]
```

### 9.3 节点创建与关联建立

**节点来源**：所有节点均由**外部系统传入的聊天记录**经语义切割后创建。
- 记忆系统本身不生成内容
- 不主动创建示例节点或系统节点
- 初始状态为空，节点随外部输入逐步积累

```
外部系统传入的聊天记录
    │
    ▼ 语义切割
    │
    ▼ 多个小段
    │
    ├─► 小段1：压缩 → 提取关键词 → 创建记忆节点
    ├─► 小段2：压缩 → 提取关键词 → 创建记忆节点
    └─► 小段3：压缩 → 提取关键词 → 创建记忆节点
            │
            ▼ 建立关联
                ├─► 与当前所有关注点：强度 = 1.0
                └─► 同一切割来源的节点之间：双向关联，关系名"上文"/"下文"
```

**关联规则说明**：
- 与关注点关联：强度固定为1，不衰减（受关注点保护）
- 切割节点间关联：强度0.5，正常衰减，表示语义连贯性

### 9.4 从上下文到记忆网络

**完整流程**（外部系统驱动）：
```
智能体对话产生聊天记录
    │
    ▼ 外部系统监控上下文长度
    │
    ▼ 达到阈值（如80%）
    │
    ▼ 将超出部分提交给记忆系统
    │
    ▼ 记忆系统执行语义切割 → 多个小段
    │
    ├─► 小段1 ──┐
    ├─► 小段2 ──┼──► 建立关联（强度0.5）
    ├─► 小段3 ──┤
    │           │
    ▼           ▼
与当前所有关注点建立关联（强度1.0，语义关系名）
    │
    ▼ 加入记忆网络（从空网络开始逐步积累）
```

**关键设计**：
- 记忆系统**被动接收**：不主动抓取或生成内容
- **空启动**：系统启动时网络为空，所有节点来自外部传入
- **聊天记录是唯一来源**：节点内容由真实的对话历史构成

---

## 10. 节点生命周期（数学视角）

```
创建节点
    │
    ▼ 初始状态
┌─────────────────────────────────────┐
│ 内容 = 完整内容                      │
│ 初始关联强度 = 0.5                   │
│ 创建时间 = t₀                        │
│ 扫描次数 = 0                         │
└─────────────────────────────────────┘
    │
    ▼ 时间演化（每单位时间）
    
    重要性 = Σ sᵢ
    │
    ├─► 所有关联强度 ×= decay_rate
    ├─► 移除强度 < 0.01 的关联
    ├─► 更新内容（按重要性比例保留，目标字数 = min(重要性,1) × 原文）
    ├─► 更新短语/关键词
    ├─► 扫描次数 += 1
    │
    ▼ 事件触发
    
    收到相关内容 ──► 新关联建立（强度=0.5）──► 重要性增加
    
    │
    ▼ 终止条件
    
    重要性 = 0 ──► 节点遗忘（无关联）
    或
    内容压缩至空 ──► 节点遗忘
```

---

## 11. 待明确的数学定义

### 11.1 重要性公式

需要确定：

- [x] 函数形式：直接求和 `重要性 = Σsᵢ`
- [x] 取值范围：[0, ∞)
- [x] 压缩公式：目标字数 = min(重要性, 1) × 原文

### 11.2 压缩过程的定义

#### 11.2.1 触发机制：内部触发

压缩由**记忆系统内部机制**触发，外部无需关心。

**触发时机**：
每次 `remember()` 调用完成后，记忆系统内部自动触发一次压缩。

**触发流程**：

```
外部调用 remember(messages)
    │
    ▼ 加入队列，等待处理
    │
    ▼ 队列处理器执行
        │
        ▼ 语义切割 → 创建节点 → 建立关联
        │
        ▼ 节点创建完成后
            │
            └─► 触发一次压缩（内部机制）
                │
                ▼ 将压缩任务加入队列
                │
                ▼ 执行压缩（时间片调度）
```

**关键设计**：
- 压缩**不是立即执行**，而是进入系统队列
- 每次创建新记忆后自动触发压缩，保持系统活跃
- **时间的影响蕴含在多次压缩中**，不需要显式的时间参数计算

#### 11.2.2 每次压缩的执行方式

- 内容按比例缩减（由重要性决定）
- 更新短语/关键词
- 关联强度衰减

#### 11.2.3 压缩的粒度与调度

**时间片调度机制**：

| 参数 | 值 | 说明 |
|------|-----|------|
| 时间片长度 | `time_slice` | 每个智能体的单次压缩时长 |

**调度流程**：
```
系统启动压缩
    │
    ▼ 分配时间片给智能体A（30秒）
    │
    ▼ 智能体A开始压缩其记忆节点
    │   （逐个节点串行处理）
    │
    ▼ 时间片结束（30秒到）
    │   无论处理了多少节点，立即暂停
    │
    ▼ 切换到智能体B，分配时间片
    │
    ▼ ...循环直到所有智能体处理完毕
```

**特性**：
- 压缩任务**可暂停、可随时停止**
- 最小粒度：**单个节点**
- 调度方式：时间片轮转，在智能体间**分时执行**
- 一个智能体的完整压缩可能分布在**多个时间片**内完成

**并行性**：
- 节点之间**无依赖**，理论上可并行处理
- 实际实现：小模型计算速度有限，采用**串行处理**

#### 11.2.4 扫描顺序与长期记忆（方案选择）

有两种实现方案，根据性能和资源需求选择：

##### 方案A：固定节点数（推荐）

**核心思想**：系统维护固定数量的节点槽位，新节点需要创建时，复用最不重要的节点槽位。

```
固定节点池（如10000个槽位）
    │
    ▼ 需要创建新节点
    │
    ▼ 找到当前最不重要的节点（重要性最低）
    │   （无需精确排序，随机采样估计即可）
    │
    ▼ 复用该槽位：
        - 清空原节点数据
        - 断开原节点关联（懒删除）
        - 生成新ID
        - 写入新节点数据
```

**优势**：
- 内存和存储占用固定，无上限风险
- 无需维护scan_count排序，性能稳定
- 旧连接指向旧ID，物理位置相同但ID变化，天然识别"遗忘"

**适用场景**：资源受限、长期运行的系统

##### 方案B：扫描次数排序

**扫描次数**（`scan_count`）：记录节点被压缩扫描的次数。

**扫描顺序规则**：
```
优先扫描 scan_count 小的节点
    │
    ▼ 次数少的节点先被处理
    │
    ▼ 处理完后 scan_count + 1
    │
    ▼ 下次扫描时排到后面
```

**性能优化**：
- 不需要绝对精确的排序
- 可采用概率数据结构（如Skip List）或随机采样估计
- 有限次扫描后统计上趋近一致即可

**长期记忆形成机制**：

| 扫描次数 | 效果 |
|----------|------|
| 少 | 容易被扫描到，容易被压缩 |
| 多 | 难以被扫描到，难以被压缩 |

**本质**：
- 被反复扫描的记忆 → 扫描次数增加 → 扫描间隔变长 → 压缩频率降低
- 形成**长期记忆**：不是不被遗忘，而是遗忘速度极慢

**适用场景**：节点数量可控、需要精确长期记忆区分的系统

#### 11.2.5 删除阈值机制

**直接删除条件**：
```
目标字数 = 原始字数 × min(重要性, 1)

如果 目标字数 < delete_threshold → 直接删除节点
```

**作用**：
- 避免对过短内容调用小模型压缩
- 减少无效计算
- 快速清理碎片记忆

### 11.3 关联强度演化

**已确定**：
- ✅ 新关联初始强度：`link_initial_strength` = 0.5
- ✅ 关联强度衰减：每次压缩时乘以 `decay_rate`
- ✅ 关联断裂阈值：强度 < 0.01

### 11.4 内容压缩实现

#### 压缩算法：小模型语义压缩

**保留比例计算**：
```
目标字数 = 原始字数 × min(重要性, 1)
```

| 重要性 | 效果 |
|----------|------|
| 0 | 保留0%（直接删除节点/遗忘）|
| 0.5 | 保留50% |
| 1 | 保留100%（不压缩）|
| > 1 | 保留100%（受到保护）|

**压缩流程**：
```
原始文本
    │
    ▼ 计算目标字数 = len(原文) × min(重要性, 1)
    │
    ▼ 判断：目标字数 < delete_threshold ?
    │
    ├─ 是 → 直接删除节点
    │
    └─ 否 → 调用内置小模型
            输入：原文 + 目标字数要求
            输出：压缩后文本
            │
            ▼ 替换节点内容
```

**删除阈值**：当目标字数低于此阈值时，直接删除节点而非压缩

**小模型职责**：
- 理解原文语义
- 在指定字数限制下保留核心信息
- 返回简洁、连贯的压缩文本

**"不可理解"的量化定义**：
```
不可理解 ⇔ 目标字数 < delete_threshold
```
- 当压缩后文字长度小于10个字符时，内容已无法承载有效语义
- 此时直接删除节点，而非进行无意义的压缩

### 11.5 边界情况处理

#### 节点删除后的关联处理

**懒删除策略**：
- 节点被删除时，**不主动清理**指向它的关联
- 当其他节点访问该关联时，发现目标节点不存在 → **自动删除该关联**

```
节点A → 关联 → [节点B（已删除）]
    │
    ▼ 访问关联时检测到节点B不存在
    │
    ▼ 自动删除节点A的这条关联
```

#### scan_count 上限

**无上限设计**：
- `scan_count` 会一直增长，不考虑上限
- 理论上，当节点非常多时，两次扫描同一节点的时间差可能达到**几十年**
- 这正是长期记忆的形成机制：扫描次数越高，被扫描频率越低

#### 小模型压缩失败处理

**重试机制**：
```
调用小模型压缩
    │
    ▼ 失败
    │
    ▼ 重试（最多15次）
    │
    ├─ 成功 → 更新节点内容
    │
    └─ 15次均失败 → 放弃本次压缩，保留原内容
```

---

## 12. 对比：数学化 vs 逻辑化

| 特性 | 数学化设计 | 逻辑化设计 |
|------|-----------|-----------|
| 状态变化 | 连续渐变 | 离散跳转 |
| 决策 | 公式计算 | if-else判断 |
| 遗忘 | 重要性=0的自然结果 | delete操作 |
| 关联等级 | 连续强度值 | 强/中/弱枚举 |
| 可预测性 | 可微分、可优化 | 硬编码规则 |

---

**最后更新**：2026-02-06

**记录人**：用户

**变更记录**：
- 新增：持久化与生命周期概念（0.3节）
- 新增：记忆写入接口 remember()（第8节）
- 新增：记忆的建立章节（原第8节，现第9节）
- 新增：语义切割机制（8.2、8.3）
- **修改**：新节点与关注点关联的关系名由小模型语义分析确定（8.1、8.3）
- **删除**：关注点之间不再自动建立特殊关联
- 新增：切割节点间关联强度=0.5规则（9.3）
- 新增：外部系统触发判断说明（8.1）
- 新增：边界情况处理（10.5）
- 新增：节点删除后关联懒删除机制（10.5）
- 新增：小模型压缩失败重试15次机制（10.5）
- 新增：扫描次数与长期记忆机制（2、9、10.2.4）
- 新增：扫描顺序优先处理次数少的节点（10.2.4）
- 新增：关注点机制（第8节）
- 新增：关注点来源于聊天记录关键实体（8.3）
- 新增：关键词要求：名词/代词，指代事物/领域（7.3）
- 更新：回忆函数增加 `depth` 参数，BFS搜索（6.1）
- 更新：回忆函数改为异步函数，后台线程执行（6.1）
- 新增：与现有方案的区别对比（1.2）
- 新增：回忆函数接口定义（第7节）
- 新增：时间片调度机制，每个智能体30秒（10.2.3）
- 新增：删除阈值机制（10.2.5、10.4）
- 新增：压缩粒度与调度机制（10.2.3）
- 新增：压缩可暂停、可随时停止（10.2.3）
- 新增：关联衰减速率变量及衰减机制（4.1、10.3）
- 新增：关联断裂阈值 0.01（4.1）
- 新增：小模型语义压缩方案（10.4）
- 新增：压缩比例计算公式（10.4）
- **修改**：压缩触发机制改为内部机制，每次 remember 完成后自动触发（11.2.1）
- 新增：压缩排队执行机制（10.2.1）
- 新增：强化机制（6.1-6.3）
- 修改：时间演化总览拆分为自然退化与强化干预（7.1-7.2）
- 新增：待明确问题分类（8.1-8.4）
- 重大更新：重新定义"重要性"数学化概念（3.1-3.3）
- 新增：数学化设计原则（第6节）
- 新增：节点生命周期数学视角（第10节）
- 新增：待明确的数学定义（第11节）
- 新增：数学化vs逻辑化对比（第12节）
- **重要修正**：时间不再参与重要性计算，仅作为元数据（3.1、5.3、7.1-7.2）
- 新增：系统定位与边界（第0节）
- 新增：智能体隔离原则（0.1）
- 新增：执行模型设计（0.2）
- 更新：对比表格增加智能体隔离和执行模型（1.2）
- 更新：recall异步说明，体现队列机制（6.1）
- **重要设计**：记忆系统不在智能体间共享，每个智能体独立实例
