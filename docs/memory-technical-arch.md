# 记忆系统技术架构文档

本文档描述记忆系统的技术架构设计，包含技术选型、模块划分、接口契约、核心流程和配置参数。不包含具体代码实现。

---

## 1. 技术架构概述

### 1.1 技术栈选型

| 组件 | 选型 | 版本要求 | 说明 |
|------|------|----------|------|
| **图数据库** | LevelGraph | ^4.0.0 | 基于LevelDB的嵌入式图数据库，支持RDF三元组存储 |
| **存储后端** | classic-level | ^1.0.0 | LevelDB的Node.js/Bun适配器 |
| **运行时** | Bun | ≥1.0 | 高性能JavaScript运行时 |
| **压缩服务** | 内置小模型 | - | 独立Worker线程执行，与主逻辑解耦 |
| **序列化** | JSON | - | 节点内容存储格式 |

**选型理由**：
- LevelGraph提供六重索引（Hexastore），天然支持图的遍历查询
- 嵌入式数据库，无需独立服务，每个智能体独立数据目录
- RDF三元组模型与记忆系统的「节点-关联」概念高度契合

### 1.2 系统架构

#### 多智能体隔离架构

```
┌─────────────────────────────────────────────────────────────┐
│                         系统层                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   智能体A    │  │   智能体B    │  │   智能体C    │  ... │
│  │ ┌──────────┐ │  │ ┌──────────┐ │  │ ┌──────────┐ │      │
│  │ │ 记忆系统A │ │  │ │ 记忆系统B │ │  │ │ 记忆系统C │ │      │
│  │ │ (独立实例)│ │  │ │ (独立实例)│ │  │ │ (独立实例)│ │      │
│  │ └──────────┘ │  │ └──────────┘ │  │ └──────────┘ │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
```

**隔离原则**：
- 每个智能体拥有独立的记忆系统实例
- 数据存储在独立目录，不共享数据库连接
- 一个智能体的记忆操作不影响其他智能体

#### 单智能体内部架构

```
┌─────────────────────────────────────────────────────────────┐
│                      智能体进程                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │                  MemoryManager                        │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌──────────────┐  │  │
│  │  │  NodeStore  │  │  LinkStore  │  │ FocusManager │  │  │
│  │  │  (节点存储)  │  │  (关联存储)  │  │ (关注点管理) │  │  │
│  │  └─────────────┘  └─────────────┘  └──────────────┘  │  │
│  │  ┌─────────────┐  ┌──────────────────────────────┐  │  │
│  │  │SearchEngine │  │   CompressionScheduler       │  │  │
│  │  │  (搜索引擎)  │  │     (压缩调度器)              │  │  │
│  │  └─────────────┘  └──────────────────────────────┘  │  │
│  └──────────────────────────────────────────────────────┘  │
│                            │                                │
│  ┌─────────────────────────▼────────────────────────────┐  │
│  │              LevelGraph (Graph DB)                   │  │
│  │         每个智能体独立的数据库文件/目录               │  │
│  └──────────────────────────────────────────────────────┘  │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐  │
│  │         Compression Worker (独立线程)                 │  │
│  │              小模型语义压缩服务                       │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

### 1.3 模块职责

| 模块 | 核心职责 | 功能边界 |
|------|----------|----------|
| **MemoryManager** | 统一入口，协调各模块 | 接收外部请求，分发到子模块，不处理具体业务逻辑 |
| **NodeStore** | 节点生命周期管理 | 创建、读取、更新、删除节点；管理节点内容、短语、关键词、扫描次数 |
| **LinkStore** | 关联生命周期管理 | 创建、查询、删除关联；计算节点重要性；执行关联强度衰减 |
| **FocusManager** | 关注点维护 | LRU维护关注点列表（最多5个）；关注点保护机制 |
| **SearchEngine** | 记忆检索 | 基于关注点的关联强度搜索；关键词匹配；结果格式化 |
| **CompressionScheduler** | 压缩调度 | 决定压缩时机和节点；协调小模型压缩服务；维护扫描顺序 |

### 1.4 执行模型

**业务层线性 + 记忆层异步队列**

| 层级 | 执行模型 | 说明 |
|------|----------|------|
| **业务逻辑层** | 线性执行 | 智能体业务代码顺序调用记忆接口，不并发 |
| **记忆系统层** | 异步队列 | 记忆系统内部维护任务队列，串行处理所有操作 |

**设计理由**：
- 业务层线性保证思维因果一致性
- 记忆层异步队列保证内部状态一致性，耗时操作不阻塞业务
- 即使业务层意外并发调用，队列保证操作顺序执行

---

## 2. 数据模型设计

### 2.1 概念模型

#### 记忆节点（Node）

| 属性 | 类型 | 说明 | 变化趋势 |
|------|------|------|----------|
| `id` | string | 唯一标识符，系统生成 | 不变 |
| `content` | string | 记忆内容（来自聊天记录，经小模型处理） | 随重要性降低被压缩 |
| `phrase` | string | 短语摘要（10-20字，小模型提取） | 随内容压缩同步更新 |
| `keywords` | string[] | 关键词列表（3-5个，小模型提取） | 随内容压缩同步更新 |
| `createdAt` | number | 创建时间戳（毫秒） | 不变 |
| `scanCount` | number | 被压缩扫描的次数 | 每次扫描+1 |

#### 关联（Link）

| 属性 | 类型 | 说明 | 变化趋势 |
|------|------|------|----------|
| `from` | string | 源节点ID | 不变 |
| `to` | string | 目标节点ID | 不变 |
| `strength` | number | 关联强度 [0, 1] | 每次压缩时衰减 |
| `relation` | string | 关系名称（可选，如"focus-link"） | 不变 |

#### 关注点（Focus）

| 属性 | 类型 | 说明 |
|------|------|------|
| `nodeId` | string | 被关注的节点ID |
| `order` | number | LRU顺序（1=最老，5=最新） |

**关注点约束**：
- 数量上限：5个
- 保护效果：被关注的节点不被压缩，与关注点关联强度锁定为1

### 2.2 存储方案

**存储结构**：RDF三元组（subject-predicate-object）

```
# 节点属性示例
node:{id}  rdf:type        memory:Node
node:{id}  memory:content  "文本内容"
node:{id}  memory:phrase   "短语摘要"
node:{id}  memory:keywords "[\"关键词1\", \"关键词2\"]"
node:{id}  memory:createdAt "1707123456789"
node:{id}  memory:scanCount "5"

# 关联示例
node:{from}  memory:link    node:{to}
link:{from}:{to}  rdf:type  memory:Link
link:{from}:{to}  memory:strength  "0.8"
link:{from}:{to}  memory:relation  "focus-link"

# 关注点示例
focus:current  rdf:type   memory:FocusList
focus:current  memory:member  node:{id}
focus:current  memory:order   "1"
```

**存储目录结构**（每个智能体独立）：
```
memory_data/
├── agent_001/           # 智能体A的数据目录
│   ├── nodes/           # 节点数据（LevelDB内部管理）
│   ├── links/           # 关联数据
│   ├── index/           # 索引数据
│   └── meta.json        # 元数据（版本、统计信息）
├── agent_002/           # 智能体B的数据目录
└── ...
```

### 2.3 持久化实现

**初始化流程**：
```
MemoryManager.initialize(agentId)
    │
    ▼ 构造数据库路径：memory_data/{agentId}/
    │
    ▼ 检查路径是否存在
    │
    ├─ 存在 → 打开已有LevelGraph数据库，加载数据
    │
    └─ 不存在 → 创建新文件夹，初始化空数据库
    │
    ▼ 启动队列处理器
    │
    ▼ 返回初始化完成
```

**关闭流程**：
```
MemoryManager.close()
    │
    ▼ 停止队列处理器（等待当前任务完成）
    │
    ▼ 确保内存中数据写入硬盘
    │
    ▼ 关闭LevelGraph数据库连接
    │
    ▼ 返回关闭完成
```

**持久化特性**：
- 数据实时写入LevelDB（LevelDB保证数据持久性）
- 系统崩溃后可通过重新初始化恢复数据
- 每个智能体数据完全隔离，支持独立备份/迁移

### 2.4 索引需求

LevelGraph的Hexastore自动提供六重索引，满足以下查询模式：

| 查询模式 | 用途 |
|----------|------|
| (S-P-?) | 查询节点所有属性 |
| (S-?-O) | 查询特定属性值 |
| (?-P-O) | 查询所有指向某节点的关联（反向查询） |
| (S-P-?) | 查询节点的所有出边（正向关联） |

**附加索引需求**（如需性能优化）：
- 按`scanCount`排序的节点索引（用于压缩调度）
- 关键词倒排索引（加速检索时的关键词匹配）

---

## 3. 模块接口定义

### 3.1 MemoryManager（统一入口）

**职责**：封装内部复杂度，对外提供简洁接口

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `initialize(agentId: string)` | 智能体唯一标识 | Promise<void> | 初始化系统，加载数据，启动队列处理器。使用agentId作为数据库文件夹名 |
| `remember(messages)` | 与大模型通信的聊天记录数组 | void | 将记忆创建任务加入队列，立即返回，无返回值 |
| `recall(keywords, relations, depth)` | 关键词数组、关系筛选、搜索深度 | Promise<string> | 将回忆任务加入队列，返回语义化文本 |
| `triggerCompression()` | - | Promise<void> | 【内部使用】每次 remember 完成后自动触发，外部无需调用 |
| `close()` | - | Promise<void> | 关闭数据库连接，确保数据持久化到硬盘，停止队列处理器 |

**MemoryManager 内部私有方法**（由内部队列处理器调用）：

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `store(segments, phrases, keywords)` | 小模型处理后的切割结果 | Promise<string[]> | 创建记忆节点，返回节点ID列表。外部不直接调用，通过 remember() 入队后由队列处理器调用 |

**调用约定**：
- 所有接口均为异步，返回Promise
- 请求进入内部任务队列，串行执行
- 即使业务层并发调用，也保证内部顺序执行

### 3.2 NodeStore（节点存储）

**职责**：节点的CRUD，内容更新，扫描计数管理

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `createNode(content, phrase, keywords)` | 内容、短语、关键词 | Promise<Node> | 创建新节点 |
| `getNode(id)` | 节点ID | Promise<Node \| null> | 获取节点，不存在返回null |
| `updateContent(id, newContent, newPhrase, newKeywords)` | 节点ID、新内容、新短语、新关键词 | Promise<void> | 更新节点内容（压缩后调用） |
| `deleteNode(id)` | 节点ID | Promise<void> | 删除节点（重要性=0时调用） |
| `incrementScanCount(id)` | 节点ID | Promise<void> | 增加扫描次数 |
| `getAllNodes()` | - | Promise<Node[]> | 获取所有节点（压缩调度使用） |

**固定节点数方案专用**（可选实现）：

| 方法 | 说明 |
|------|------|
| `createSlot(slotId)` | 预创建空槽位 |
| `activateSlot(slotId, content, phrase, keywords)` | 激活空闲槽位为新节点 |
| `reuseSlot(slotId, content, phrase, keywords)` | 复用最不重要的槽位 |

### 3.3 LinkStore（关联存储）

**职责**：关联的CRUD，重要性计算，关联强度衰减

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `createLink(from, to, strength, relation?)` | 源节点ID、目标节点ID、强度、关系名称 | Promise<void> | 创建双向关联 |
| `getNodeLinks(nodeId)` | 节点ID | Promise<Link[]> | 获取节点的所有有效关联（强度≥0.01） |
| `calculateImportance(nodeId)` | 节点ID | Promise<number> | 计算节点重要性（所有关联强度之和） |
| `decayAllLinks(nodeId)` | 节点ID | Promise<void> | 衰减该节点的所有关联强度 |
| `deleteLink(from, to)` | 源节点ID、目标节点ID | Promise<void> | 删除关联（强度<0.01时调用） |
| `detectBrokenLinks(nodeId)` | 节点ID | Promise<{validLinks, danglingLinks}> | 检测悬空关联（目标节点已删除） |

**悬空关联说明**：
- 目标节点被删除后，指向它的关联成为"悬空关联"
- 悬空关联不自动删除，保留"曾经记得"的语义
- 智能体可通过danglingLinks感知自己遗忘的内容

**关联强度的不对称性**：
- A→B的关联强度与B→A的关联强度**相互独立**
- 压缩时各自衰减，可能出现不对称（如A→B为0.8，B→A为0.6）
- 这是正常且被允许的，反映记忆的不同方向性

### 3.4 FocusManager（关注点管理）

**职责**：从聊天记录中提取关键实体，LRU维护关注点列表，关注点保护

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `initialize()` | - | Promise<void> | 从存储加载关注点列表 |
| `getFocusList()` | - | string[] | 获取当前关注点ID列表（LRU顺序） |
| `isFocus(nodeId)` | 节点ID | boolean | 判断是否为关注点 |
| `extractAndUpdateFocus(segments)` | 文本片段数组 | Promise<void> | 从segments提取关键实体，更新关注点列表 |

**关注点本质**：
- 关注点是**被标记为"关注"的普通记忆节点**
- 作为搜索回忆的起始点
- 随着对话进行，新创建的记忆节点成为关注点

**关注点来源**：
- 最新的maxFocusCount个新创建的记忆节点成为关注点
- 在 remember 时更新
- recall 不更新关注点
- **不查找已有节点**：即使内容重复也创建新节点，新节点直接成为关注点

**LRU实现**：使用队列顺序（非时间戳）
- 队列头部 = 最新关注点
- 队列尾部 = 最老关注点
- 新关注点加入头部
- 超出maxFocusCount时，淘汰尾部的最老关注点
- 取消关注后，其出边关联从**下次压缩开始**正常衰减

**关注点行为**：
- 关注点之间不自动建立特殊关联
- 系统首次启动时关注点列表为空

### 3.5 SearchEngine（搜索引擎）

**职责**：基于路径强度的最佳优先搜索，关键词匹配，结果格式化

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `search(keywords, relations, depth)` | 关键词数组、关系筛选、搜索深度 | Promise<SearchResult[]> | 基于路径强度最佳优先搜索，返回匹配结果 |
| `formatResults(results)` | 搜索结果数组 | string | 格式化为语义化文本，包含悬空关联的感知描述 |

**SearchResult 结构**：
```typescript
interface SearchResult {
    node: Node;              // 匹配的记忆节点
    matchedKeywords: string[]; // 匹配的关键词
}
```

**悬空关联感知**：
- 搜索过程中检测到悬空关联（指向已删除节点的关联）时，记录该信息
- `formatResults` 格式化时，对悬空关联生成感知描述：
  - 示例：`"[记忆] 它有个XX，但我想不起来了"`
  - 示例：`"[记忆] 与某个已遗忘的事物有关联"`
- 这体现"记得曾经记得"的语义，让智能体感知自己的遗忘

**搜索行为**：
- **关注点顺序**：从最新关注点到最老关注点依次扫描
- **路线强度**：路径上所有关联强度的乘积
- **搜索算法**：最佳优先搜索（按路线强度降序）
- **深度限制**：在指定深度范围内扫描所有可达节点
- **匹配**：关键词在content或keywords中匹配（不区分大小写）
- **关系筛选**：如提供relations，只返回具有指定关系的关联路径
- **去重**：同一节点只返回一次（首次发现的路径）

**返回格式**（语义透明，不含技术细节）：
```
[记忆] 昨天讨论了用户系统的登录模块设计，决定采用JWT方案。
---
[记忆] 前端组提到需要支持第三方登录，这个需求优先级待定。
---
[记忆] 架构评审时强调了安全性，建议使用短时效token。
```

- 每段记忆以 `[记忆]` 开头
- 记忆之间用 `---` 分隔
- 内容保持原始语义，不包含节点ID、匹配度等技术信息
- 格式对大模型友好，无需额外解析

### 3.6 CompressionScheduler（压缩调度器）

**职责**：决定压缩时机和节点，协调小模型压缩

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `runCompressionSlice()` | - | Promise<void> | 执行一轮压缩（一个时间片） |

**调度策略**（二选一实现）：

**方案A：固定节点数（性能优先）**
- 预分配固定数量的节点槽位（如10000个）
- 新节点需要时复用最不重要的槽位
- 压缩时随机采样估计重要性，优先压缩不重要的

**方案B：扫描次数排序（精确优先）**
- 按`scanCount`排序，少的优先处理
- 每轮压缩处理一批节点，处理完scanCount+1
- 时间片机制：每轮压缩限制执行时间

#### 压缩单节点流程

1. 检查是否为关注点：是 → 跳过（关注点不被压缩）
2. 计算重要性 = 所有关联强度之和
3. 重要性 = 0：删除节点
4. 计算目标字数 = 原始字数 × min(重要性, 1)
5. 目标字数 < 删除阈值：删除节点
6. 目标字数 ≥ 原始字数：跳过（无需压缩）
7. 调用小模型压缩内容
8. 更新节点内容、短语、关键词
9. **衰减该节点的关联强度**（但跳过：关注点→其他节点的关联永不衰减）
10. 增加扫描次数

**关注点保护机制**：
- 关注点节点本身不被压缩（步骤1跳过）
- 关注点指向其他节点的关联强度永不衰减（步骤9跳过）
- 其他节点指向关注点的关联正常衰减

---

## 4. 核心流程

### 4.1 记忆建立流程

**触发条件**：外部系统监控上下文长度，超过阈值（如80%）时触发

**流程**：
```
外部系统调用 MemoryManager.remember(messages)
    │
    ▼ 立即返回（无返回值，不阻塞）
    │
    ▼ 将任务加入内部队列
    │   任务类型：MEMORY_CREATE
    │   任务数据：messages
    │
    ▼ 队列处理器（串行执行）
        │
        ▼ 【步骤1】调用小模型语义切割
        │   输入：原始聊天记录
        │   输出：segments[]（文本片段）
        │
        ├─► 失败 → 该任务重新加入队列尾部，稍后重试
        │
        └─► 成功
            │
            ▼ 【步骤2】对每个segment调用小模型
                生成：phrase（摘要）、keywords（关键词）
            │
            ▼ 【步骤3】批量创建节点及同批次关联
                为每个segment创建节点（content, phrase, keywords）
                所有节点创建完成后：
                - 同批次节点间建立双向关联
                - 强度0.5，关系名"上文"/"下文"
            │
            ▼ 【步骤4】创建与当前关注点的关联
                对每个新节点和每个当前关注点：
                - 小模型生成关系名称（如"属于"、"关于"）
                - 失败则不写关系名
                - 创建双向关联，强度1.0
            │
            ▼ 【步骤5】更新关注点列表
                - 最新的maxFocusCount个新节点成为关注点
                - 超出上限的老关注点取消关注
                - 取消关注后，其出边关联从下次压缩开始正常衰减
            │
            ▼ 【步骤6】触发压缩
                自动触发一次压缩任务
```

**关联建立规则**：
- **同批次节点间关联**（步骤3）：强度0.5，正常衰减，关系名"上文"/"下文"
- **与当前关注点关联**（步骤4）：强度1.0（新建时），关系名由小模型生成
- **关注点 → 其他节点**：强度1.0，永不衰减（关注点保护机制）
  - 该关联**参与目标节点的重要性计算**
  - 被关注点指向的节点，重要性永远≥1，不会被压缩
- **关注点之间**：不自动建立特殊关联

**关注点更新规则**（步骤5）：
- 最新的maxFocusCount个新节点直接成为关注点
- LRU维护：新加入的关注点移到最新位置
- 超出maxFocusCount时，淘汰最老的
- 取消关注后，其出边关联从下次压缩开始正常衰减
- **不查找已有节点**：即使内容重复也创建新节点，新节点直接成为关注点

**关注点为空的处理**：
- 系统首次启动时关注点列表为空
- 此时recall返回空结果
- 首次remember后，新节点成为关注点，后续recall正常工作

### 4.2 回忆检索流程

**触发条件**：智能体思考时需要相关记忆

**流程**：
```
智能体调用 recall(keywords, relations, depth)
    │
    ▼ 进入任务队列，串行执行
    │
    ▼ 从关注点开始搜索（从最新到最老）
        │
        ├─► 关注点为空？→ 返回空结果
        │
        ├─► 全局优先队列最佳优先搜索
        │   - 从所有关注点同时开始（混着处理）
        │   - 路线强度 = 路径上关联强度乘积
        │   - 全局优先队列按路线强度降序
        │   - depth为跳数（如2表示最多2跳）
        │   - 扫描至队列为空或达到maxResults
        │
        ├─► 匹配检查：keywords在content/keywords中匹配
        ├─► 关系筛选：如提供relations，检查关联类型
        ├─► 跳过悬空关联（目标节点已删除）
        ├─► 去重：已返回的节点不再添加
        │
    ▼ 格式化结果
        │
        └─► 返回语义化文本（[记忆]...\n---\n[记忆]...）
```

**注意**：
- 回忆过程**不更新关注点**
- 关注点只在 remember 时从聊天记录中更新
- 首次使用前关注点为空，recall返回空结果
- 搜索顺序：先强路线后弱路线，先新关注点后老关注点

### 4.3 压缩调度流程

**触发条件**：每次 `remember()` 完成后，内部自动触发

**流程**：
```
remember() 处理完成（节点创建完毕）
    │
    ▼ 内部自动触发压缩
    │
    ▼ 将压缩任务加入队列
    │
    ▼ CompressionScheduler.runCompressionSlice()
        │
        ├─► 获取待压缩节点队列（根据策略A或B）
        │
        ▼ 遍历节点（时间片控制，可中断）
            │
            ├─► 跳过关注点（受保护）
            ├─► 计算重要性
            ├─► 重要性=0 → 删除节点
            ├─► 计算目标字数
            ├─► 目标字数<阈值 → 删除节点
            ├─► 调用小模型压缩（异步Worker）
            ├─► 更新节点内容
            ├─► 衰减关联强度
            └─► 增加扫描次数
```

**调度特性**：
- 可暂停、可随时停止（时间片机制）
- 每次创建新记忆后自动触发，保持系统活跃
- 压缩不阻塞业务逻辑（队列机制）

---

## 5. 配置参数

### 5.1 系统参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `maxFocusCount` | 5 | 关注点数量上限 | 决定智能体能同时关注多少事物，影响保护范围 |
| `decayRate` | 0.97 | 关联衰减速率（每次压缩） | 决定遗忘速度，越小遗忘越快 |
| `linkInitialStrength` | 0.5 | 新建关联初始强度 | 决定新记忆的初始保护程度 |
| `deleteThreshold` | 5 | 删除阈值（字符数） | 压缩后低于此值直接删除节点 |
| `linkBreakThreshold` | 0.01 | 关联断裂阈值 | 强度低于此值删除关联 |

### 5.2 压缩调度参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `timeSlice` | 30000ms | 单次压缩时间片 | 控制压缩对系统资源的占用 |
| `compressionBatchSize` | 100 | 每轮压缩处理节点数（方案A） | 控制压缩粒度 |
| `maxNodes` | 10000 | 固定节点数上限（方案A） | 内存和存储上限 |

### 5.3 小模型参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `maxRetries` | 15 | 小模型调用失败重试次数 | 保证压缩任务完成率 |
| `workerTimeout` | 300000ms | Worker调用超时时间 | 防止无限等待 |

### 5.4 搜索参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `defaultSearchDepth` | 2 | 默认搜索深度（跳数） | 平衡召回率和性能 |
| `maxSearchResults` | 100 | 单次搜索最大结果数 | 控制返回结果数量，0表示无限制 |

### 5.5 队列参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `maxQueueSize` | 1000 | 任务队列最大长度 | 队列满时新任务入队失败 |

---

## 6. 小模型交互设计

### 6.1 任务类型

小模型承担两个核心任务：

| 任务 | 触发时机 | 输入 | 输出 |
|------|----------|------|------|
| **语义切割** | 建立记忆前 | 长文本（聊天记录） | 文本片段数组（segments） |
| **内容处理** | 节点创建/压缩时 | 原文、目标字数（可选） | content, phrase, keywords |
| **关系名提取** | 建立节点与关注点关联时 | 节点内容、关注点内容 | 关系名称（如"关于"、"涉及"） |

### 6.2 语义切割任务

**职责**：
- 将长文本切分为语义完整的小段
- 进行代词消解（将"他/她/它"替换为明确指代对象）

**输入**：原始聊天记录文本

**输出要求**：
- segments: string[]，每个片段语义完整
- 每段长度建议不超过200字符
- 代词已消解，避免后续回忆时指代不明

**失败处理**：
- 语义切割失败 → 不做任何处理（不创建节点）
- 将任务重新加入队列尾部
- 调度处理其他智能体任务
- 下次轮到该智能体时从语义切割处重新开始

### 6.3 内容处理任务

**职责**：
- 提取/生成短语摘要
- 提取关键词
- 如提供目标字数，压缩内容至目标长度

**输入**：
- text: string，原文
- targetLength?: number，目标字数（可选，未提供则保持原文）

**输出要求**：
- content: string，处理后的内容（如有目标字数则压缩）
- phrase: string，短语摘要（10-20字）
- keywords: string[]，关键词列表（3-5个，名词或名词短语）

### 6.4 关系名提取任务

**职责**：
- 分析新节点与关注点之间的语义关系
- 生成简洁的关系名称描述

**输入**：
- nodeContent: string，新节点内容
- focusContent: string，关注点内容

**输出要求**：
- relation: string，关系名称（2-4字）
- 示例："属于"、"关于"、"涉及"、"讨论"、"提到"

**使用场景**：
当创建新节点后，需要与当前所有关注点建立关联时，对每个关注点调用此任务确定关系名。

### 6.5 重试策略

**失败定义**：
- 小模型服务不可用（网络错误、服务崩溃）
- 返回格式不符合预期（无法解析JSON）
- 返回内容明显错误（空内容、乱码）

**重试机制**：
- 最大重试次数：15次
- 退避策略：指数退避（1s, 2s, 4s, ...，上限30s）
- 最终失败处理：保留原内容，记录错误日志，继续后续流程

---

## 7. 部署与依赖

### 7.1 依赖安装

```bash
# 核心依赖
bun install levelgraph classic-level uuid

# 开发依赖
bun install -d @types/uuid
```

### 7.2 系统要求

| 项目 | 要求 |
|------|------|
| 运行时 | Bun ≥ 1.0 或 Node.js ≥ 18 |
| 内存 | 取决于记忆数据量和节点数上限 |
| 磁盘 | SSD推荐，存储需求 = 节点数 × 平均内容大小 |
| 操作系统 | Linux/macOS/Windows（LevelDB支持） |

### 7.3 小模型服务

小模型作为独立服务运行，记忆系统通过HTTP API调用：

- 支持本地部署（如Ollama）或远程API
- 建议模型：7B级别中文模型（如Qwen2.5:7b）
- 服务地址通过环境变量配置

---

## 8. 性能考量

### 8.1 存储性能

- LevelDB的LSM树结构适合写密集型场景（记忆创建）
- 读性能通过Hexastore六重索引保障
- 大数据量时考虑添加关键词倒排索引

### 8.2 压缩性能

- 压缩是资源密集型操作（小模型调用）
- 时间片机制防止压缩占用过多资源
- Worker线程隔离，不影响主流程响应

### 8.3 搜索性能

- 搜索深度默认限制为2，控制查询范围
- 从关注点出发，使用最佳优先搜索（优先队列）
- 路线强度实时计算，优先遍历强关联路径
- 关键词匹配可在数据库层过滤，减少数据传输
- 去重使用HashSet，保证O(1)查询效率

---

## 9. 扩展点

### 9.1 存储后端替换

如需替换LevelGraph：
- 实现NodeStore和LinkStore接口
- 保持RDF三元组语义或自定义存储模型
- 关注点：事务支持、图遍历性能、存储效率

### 9.2 压缩策略替换

- 当前基于重要性比例压缩
- 可扩展：基于语义的智能压缩（保留关键句）
- 可扩展：多层级压缩（先摘要比率，再压缩内容）

### 9.3 检索策略扩展

- 当前基于关键词匹配
- 可扩展：向量相似度检索（并行或替代）
- 可扩展：时间范围筛选

---

## 10. 边界情况处理

### 10.1 搜索循环关联处理

**问题**：节点间可能存在循环关联（A→B→C→A）

**处理机制**：
- 搜索时使用 `visited` 集合记录已访问的节点ID
- 已访问过的节点不再重复遍历，避免无限循环
- 代码实现：
```typescript
const visited = new Set<string>();
function search(nodeId: string) {
    if (visited.has(nodeId)) return;
    visited.add(nodeId);
    // 继续遍历...
}
```

### 10.2 队列深度限制与溢出处理

**配置参数**：
| 参数名 | 默认值 | 说明 |
|--------|--------|------|
| `maxQueueSize` | 1000 | 任务队列最大长度 |

**处理机制**：
- 队列满时，新任务入队失败
- `remember()` 返回"队列已满"错误（虽然返回void，但通过日志/事件通知）
- 外部系统需根据情况调整调用频率

### 10.3 搜索结果去重

**问题**：同一节点可能通过不同路径被多次发现

**处理机制**：
- 使用 `visited` 集合记录已返回的节点
- 同一节点只返回一次
- 保留首次发现的路径信息

### 10.4 关联断裂时机

**处理机制**：
- 压缩时衰减关联强度后立即检查
- 强度 < `linkBreakThreshold`（0.01）时立即标记为断裂
- 断裂的关联：
  - 不再参与后续搜索
  - 不参与重要性计算
  - 保留在数据库中（懒删除）

### 10.5 语义切割失败处理

**处理机制**：
- 失败时不创建节点
- 任务重新入队，稍后重试
- 详见第6.2节

---

**最后更新**：2026-02-06
