# 记忆系统技术架构文档

本文档描述记忆系统的技术架构设计，包含技术选型、模块划分、接口契约、核心流程和配置参数。不包含具体代码实现。

---

## 1. 技术架构概述

### 1.1 技术栈选型

| 组件 | 选型 | 版本要求 | 说明 |
|------|------|----------|------|
| **图数据库** | LevelGraph | ^4.0.0 | 基于LevelDB的嵌入式图数据库，支持RDF三元组存储 |
| **存储后端** | classic-level | ^1.0.0 | LevelDB的Node.js/Bun适配器 |
| **运行时** | Bun | ≥1.0 | 高性能JavaScript运行时 |
| **压缩服务** | 内置小模型 | - | 独立Worker线程执行，与主逻辑解耦 |
| **序列化** | JSON | - | 节点内容存储格式 |

**选型理由**：
- LevelGraph提供六重索引（Hexastore），天然支持图的遍历查询
- 嵌入式数据库，无需独立服务，每个智能体独立数据目录
- RDF三元组模型与记忆系统的「节点-关联」概念高度契合

### 1.2 系统架构

#### 多智能体隔离架构

```
┌─────────────────────────────────────────────────────────────┐
│                         系统层                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   智能体A    │  │   智能体B    │  │   智能体C    │  ... │
│  │ ┌──────────┐ │  │ ┌──────────┐ │  │ ┌──────────┐ │      │
│  │ │ 记忆系统A │ │  │ │ 记忆系统B │ │  │ │ 记忆系统C │ │      │
│  │ │ (独立实例)│ │  │ │ (独立实例)│ │  │ │ (独立实例)│ │      │
│  │ └──────────┘ │  │ └──────────┘ │  │ └──────────┘ │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
```

**隔离原则**：
- 每个智能体拥有独立的记忆系统实例
- 数据存储在独立目录，不共享数据库连接
- 一个智能体的记忆操作不影响其他智能体

#### 单智能体内部架构

```
┌─────────────────────────────────────────────────────────────┐
│                      智能体进程                              │
│  ┌──────────────────────────────────────────────────────┐  │
│  │                  MemoryManager                        │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌──────────────┐  │  │
│  │  │  NodeStore  │  │  LinkStore  │  │ FocusManager │  │  │
│  │  │  (节点存储)  │  │  (关联存储)  │  │ (关注点管理) │  │  │
│  │  └─────────────┘  └─────────────┘  └──────────────┘  │  │
│  │  ┌─────────────┐  ┌──────────────────────────────┐  │  │
│  │  │SearchEngine │  │   CompressionScheduler       │  │  │
│  │  │  (搜索引擎)  │  │     (压缩调度器)              │  │  │
│  │  └─────────────┘  └──────────────────────────────┘  │  │
│  └──────────────────────────────────────────────────────┘  │
│                            │                                │
│  ┌─────────────────────────▼────────────────────────────┐  │
│  │              LevelGraph (Graph DB)                   │  │
│  │         每个智能体独立的数据库文件/目录               │  │
│  └──────────────────────────────────────────────────────┘  │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐  │
│  │         Compression Worker (独立线程)                 │  │
│  │              小模型语义压缩服务                       │  │
│  └──────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

### 1.3 模块职责

| 模块 | 核心职责 | 功能边界 |
|------|----------|----------|
| **MemoryManager** | 统一入口，协调各模块 | 接收外部请求，分发到子模块，不处理具体业务逻辑 |
| **NodeStore** | 节点生命周期管理 | 创建、读取、更新、删除节点；管理节点内容、短语、关键词、扫描次数 |
| **LinkStore** | 关联生命周期管理 | 创建、查询、删除关联；计算节点重要性；执行关联强度衰减 |
| **FocusManager** | 关注点维护 | LRU维护关注点列表（最多5个）；关注点保护机制 |
| **SearchEngine** | 记忆检索 | 基于关注点的BFS搜索；关键词匹配；结果格式化 |
| **CompressionScheduler** | 压缩调度 | 决定压缩时机和节点；协调小模型压缩服务；维护扫描顺序 |

### 1.4 执行模型

**业务层线性 + 记忆层异步队列**

| 层级 | 执行模型 | 说明 |
|------|----------|------|
| **业务逻辑层** | 线性执行 | 智能体业务代码顺序调用记忆接口，不并发 |
| **记忆系统层** | 异步队列 | 记忆系统内部维护任务队列，串行处理所有操作 |

**设计理由**：
- 业务层线性保证思维因果一致性
- 记忆层异步队列保证内部状态一致性，耗时操作不阻塞业务
- 即使业务层意外并发调用，队列保证操作顺序执行

---

## 2. 数据模型设计

### 2.1 概念模型

#### 记忆节点（Node）

| 属性 | 类型 | 说明 | 变化趋势 |
|------|------|------|----------|
| `id` | string | 唯一标识符，系统生成 | 不变 |
| `content` | string | 记忆内容（来自聊天记录，经小模型处理） | 随重要性降低被压缩 |
| `phrase` | string | 短语摘要（10-20字，小模型提取） | 随内容压缩同步更新 |
| `keywords` | string[] | 关键词列表（3-5个，小模型提取） | 随内容压缩同步更新 |
| `createdAt` | number | 创建时间戳（毫秒） | 不变 |
| `scanCount` | number | 被压缩扫描的次数 | 每次扫描+1 |

#### 关联（Link）

| 属性 | 类型 | 说明 | 变化趋势 |
|------|------|------|----------|
| `from` | string | 源节点ID | 不变 |
| `to` | string | 目标节点ID | 不变 |
| `strength` | number | 关联强度 [0, 1] | 每次压缩时衰减 |
| `relation` | string | 关系名称（可选，如"focus-link"） | 不变 |

#### 关注点（Focus）

| 属性 | 类型 | 说明 |
|------|------|------|
| `nodeId` | string | 被关注的节点ID |
| `order` | number | LRU顺序（1=最老，5=最新） |

**关注点约束**：
- 数量上限：5个
- 保护效果：被关注的节点不被压缩，与关注点关联强度锁定为1

### 2.2 存储方案

**存储结构**：RDF三元组（subject-predicate-object）

```
# 节点属性示例
node:{id}  rdf:type        memory:Node
node:{id}  memory:content  "文本内容"
node:{id}  memory:phrase   "短语摘要"
node:{id}  memory:keywords "[\"关键词1\", \"关键词2\"]"
node:{id}  memory:createdAt "1707123456789"
node:{id}  memory:scanCount "5"

# 关联示例
node:{from}  memory:link    node:{to}
link:{from}:{to}  rdf:type  memory:Link
link:{from}:{to}  memory:strength  "0.8"
link:{from}:{to}  memory:relation  "focus-link"

# 关注点示例
focus:current  rdf:type   memory:FocusList
focus:current  memory:member  node:{id}
focus:current  memory:order   "1"
```

**存储目录结构**（每个智能体独立）：
```
memory_data/
├── agent_001/           # 智能体A的数据目录
│   ├── nodes/           # 节点数据（LevelDB内部管理）
│   ├── links/           # 关联数据
│   ├── index/           # 索引数据
│   └── meta.json        # 元数据（版本、统计信息）
├── agent_002/           # 智能体B的数据目录
└── ...
```

### 2.3 索引需求

LevelGraph的Hexastore自动提供六重索引，满足以下查询模式：

| 查询模式 | 用途 |
|----------|------|
| (S-P-?) | 查询节点所有属性 |
| (S-?-O) | 查询特定属性值 |
| (?-P-O) | 查询所有指向某节点的关联（反向查询） |
| (S-P-?) | 查询节点的所有出边（正向关联） |

**附加索引需求**（如需性能优化）：
- 按`scanCount`排序的节点索引（用于压缩调度）
- 关键词倒排索引（加速检索时的关键词匹配）

---

## 3. 模块接口定义

### 3.1 MemoryManager（统一入口）

**职责**：封装内部复杂度，对外提供简洁接口

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `initialize()` | - | Promise<void> | 初始化系统，加载关注点，启动队列处理器 |
| `remember(messages)` | 与大模型通信的聊天记录数组 | void | 将记忆创建任务加入队列，立即返回，无返回值 |
| `recall(keywords, relations, depth)` | 关键词数组、关系筛选、搜索深度 | Promise<string> | 将回忆任务加入队列，返回语义化文本 |
| `triggerCompression()` | - | Promise<void> | 触发一次压缩（由外部调度调用） |
| `close()` | - | Promise<void> | 关闭数据库连接，停止队列处理器 |

**内部接口**（由队列处理器调用）：

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `store(segments, phrases, keywords)` | 小模型处理后的切割结果 | Promise<string[]> | 创建记忆节点，返回节点ID列表 |

**调用约定**：
- 所有接口均为异步，返回Promise
- 请求进入内部任务队列，串行执行
- 即使业务层并发调用，也保证内部顺序执行

### 3.2 NodeStore（节点存储）

**职责**：节点的CRUD，内容更新，扫描计数管理

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `createNode(content, phrase, keywords)` | 内容、短语、关键词 | Promise<Node> | 创建新节点 |
| `getNode(id)` | 节点ID | Promise<Node \| null> | 获取节点，不存在返回null |
| `updateContent(id, newContent, newPhrase, newKeywords)` | 节点ID、新内容、新短语、新关键词 | Promise<void> | 更新节点内容（压缩后调用） |
| `deleteNode(id)` | 节点ID | Promise<void> | 删除节点（重要性=0时调用） |
| `incrementScanCount(id)` | 节点ID | Promise<void> | 增加扫描次数 |
| `getAllNodes()` | - | Promise<Node[]> | 获取所有节点（压缩调度使用） |

**固定节点数方案专用**（可选实现）：

| 方法 | 说明 |
|------|------|
| `createSlot(slotId)` | 预创建空槽位 |
| `activateSlot(slotId, content, phrase, keywords)` | 激活空闲槽位为新节点 |
| `reuseSlot(slotId, content, phrase, keywords)` | 复用最不重要的槽位 |

### 3.3 LinkStore（关联存储）

**职责**：关联的CRUD，重要性计算，关联强度衰减

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `createLink(from, to, strength, relation?)` | 源节点ID、目标节点ID、强度、关系名称 | Promise<void> | 创建双向关联 |
| `getNodeLinks(nodeId)` | 节点ID | Promise<Link[]> | 获取节点的所有有效关联（强度≥0.01） |
| `calculateImportance(nodeId)` | 节点ID | Promise<number> | 计算节点重要性（所有关联强度之和） |
| `decayAllLinks(nodeId)` | 节点ID | Promise<void> | 衰减该节点的所有关联强度 |
| `deleteLink(from, to)` | 源节点ID、目标节点ID | Promise<void> | 删除关联（强度<0.01时调用） |
| `detectBrokenLinks(nodeId)` | 节点ID | Promise<{validLinks, danglingLinks}> | 检测悬空关联（目标节点已删除） |

**悬空关联说明**：
- 目标节点被删除后，指向它的关联成为"悬空关联"
- 悬空关联不自动删除，保留"曾经记得"的语义
- 智能体可通过danglingLinks感知自己遗忘的内容

### 3.4 FocusManager（关注点管理）

**职责**：LRU维护关注点列表，关注点保护

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `initialize()` | - | Promise<void> | 从存储加载关注点列表 |
| `getFocusList()` | - | string[] | 获取当前关注点ID列表（LRU顺序） |
| `isFocus(nodeId)` | 节点ID | boolean | 判断是否为关注点 |
| `addFocus(nodeId)` | 节点ID | Promise<void> | 添加关注点（触发LRU淘汰） |

**关注点行为**：
- 添加已存在的关注点：移到最新位置
- 数量超限（5个）：淘汰最老的，添加新的
- 关注点与所有其他关注点建立双向强度1.0关联

### 3.5 SearchEngine（搜索引擎）

**职责**：基于关注点的BFS搜索，关键词匹配，结果格式化

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `search(keywords, relations, depth)` | 关键词数组、关系筛选、搜索深度 | Promise<SearchResult[]> | BFS搜索，返回匹配结果 |
| `formatResults(results)` | 搜索结果数组 | string | 格式化为语义化文本 |

**搜索行为**：
- 起点：所有当前关注点
- 算法：BFS，深度限制为`depth`参数
- 匹配：关键词在content或keywords中匹配（不区分大小写）
- 关系筛选：如提供relations，只返回具有指定关系的关联路径

**返回格式**（语义透明，不含技术细节）：
```
[记忆] 记忆内容1
---
[记忆] 记忆内容2
---
[记忆] 记忆内容3
```

### 3.6 CompressionScheduler（压缩调度器）

**职责**：决定压缩时机和节点，协调小模型压缩

#### 接口

| 方法 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `runCompressionSlice()` | - | Promise<void> | 执行一轮压缩（一个时间片） |

**调度策略**（二选一实现）：

**方案A：固定节点数（性能优先）**
- 预分配固定数量的节点槽位（如10000个）
- 新节点需要时复用最不重要的槽位
- 压缩时随机采样估计重要性，优先压缩不重要的

**方案B：扫描次数排序（精确优先）**
- 按`scanCount`排序，少的优先处理
- 每轮压缩处理一批节点，处理完scanCount+1
- 时间片机制：每轮压缩限制执行时间

#### 压缩单节点流程

1. 计算重要性 = 所有关联强度之和
2. 重要性 ≥ 1：跳过（受保护）
3. 重要性 = 0：删除节点
4. 计算目标字数 = 原始字数 × min(重要性, 1)
5. 目标字数 < 删除阈值（10字符）：删除节点
6. 目标字数 ≥ 原始字数：跳过（无需压缩）
7. 调用小模型压缩内容
8. 更新节点内容、短语、关键词
9. 衰减所有关联强度
10. 增加扫描次数

---

## 4. 核心流程

### 4.1 记忆建立流程

**触发条件**：外部系统监控上下文长度，超过阈值（如80%）时触发

**流程**：
```
外部系统传入聊天记录
    │
    ▼ 调用小模型语义切割
    │   输入：原始聊天记录
    │   输出：segments[]（文本片段）
    │
    ▼ 对每个segment调用小模型提取phrase和keywords
    │   输出：phrases[]、keywords[][]
    │
    ▼ MemoryManager.store(segments, phrases, keywords)
        │
        ▼ 对每个segment创建节点
            │
            ├─► 创建节点（content, phrase, keywords）
            ├─► 与当前所有关注点建立双向关联（强度1.0）
            └─► 与同一切割来源的先前节点建立双向关联（强度0.5）
```

**关联建立规则**：
- 与关注点关联：强度1.0，不随压缩衰减（关注点保护）
- 切割节点间关联：强度0.5，正常衰减（语义连贯性）

### 4.2 回忆检索流程

**触发条件**：智能体思考时需要相关记忆

**流程**：
```
智能体调用 recall(keywords, relations, depth)
    │
    ▼ 进入任务队列，串行执行
    │
    ▼ 从所有关注点开始BFS搜索
        │
        ├─► 深度限制：depth参数
        ├─► 匹配检查：keywords在content/keywords中匹配
        ├─► 关系筛选：如提供relations，检查关联类型
        │
    ▼ 更新关注点
        │
        ├─► 所有匹配节点加入关注点（LRU维护，最多5个）
        ├─► 新关注点与现有关注点建立强度1.0关联
        │
    ▼ 格式化结果
        │
        └─► 返回语义化文本（[记忆]...\n---\n[记忆]...）
```

**副作用**：
- 匹配节点成为新的关注点
- 关注点更新会影响后续压缩行为

### 4.3 压缩调度流程

**触发条件**：外部调度系统定期调用`triggerCompression()`

**流程**：
```
外部系统调用 triggerCompression()
    │
    ▼ 进入任务队列
    │
    ▼ CompressionScheduler.runCompressionSlice()
        │
        ├─► 获取待压缩节点队列（根据策略A或B）
        │
        ▼ 遍历节点（时间片控制，可中断）
            │
            ├─► 跳过关注点（受保护）
            ├─► 计算重要性
            ├─► 重要性=0 → 删除节点
            ├─► 计算目标字数
            ├─► 目标字数<阈值 → 删除节点
            ├─► 调用小模型压缩（异步Worker）
            ├─► 更新节点内容
            ├─► 衰减关联强度
            └─► 增加扫描次数
```

**调度特性**：
- 可暂停、可随时停止（时间片机制）
- 多智能体环境下，每个智能体独立调度
- 压缩不阻塞业务逻辑（队列机制）

---

## 5. 配置参数

### 5.1 系统参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `maxFocusCount` | 5 | 关注点数量上限 | 决定智能体能同时关注多少事物，影响保护范围 |
| `decayRate` | 0.97 | 关联衰减速率（每次压缩） | 决定遗忘速度，越小遗忘越快 |
| `linkInitialStrength` | 0.5 | 新建关联初始强度 | 决定新记忆的初始保护程度 |
| `deleteThreshold` | 10 | 删除阈值（字符数） | 压缩后低于此值直接删除节点 |
| `linkBreakThreshold` | 0.01 | 关联断裂阈值 | 强度低于此值删除关联 |

### 5.2 压缩调度参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `timeSlice` | 30000ms | 单次压缩时间片 | 控制压缩对系统资源的占用 |
| `compressionBatchSize` | 100 | 每轮压缩处理节点数（方案A） | 控制压缩粒度 |
| `maxNodes` | 10000 | 固定节点数上限（方案A） | 内存和存储上限 |

### 5.3 小模型参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `maxRetries` | 15 | 小模型调用失败重试次数 | 保证压缩任务完成率 |
| `workerTimeout` | 300000ms | Worker调用超时时间 | 防止无限等待 |

### 5.4 搜索参数

| 参数名 | 默认值 | 说明 | 影响 |
|--------|--------|------|------|
| `defaultSearchDepth` | 2 | 默认BFS搜索深度 | 平衡召回率和性能 |

---

## 6. 小模型交互设计

### 6.1 任务类型

小模型承担两个核心任务：

| 任务 | 触发时机 | 输入 | 输出 |
|------|----------|------|------|
| **语义切割** | 建立记忆前 | 长文本（聊天记录） | 文本片段数组（segments） |
| **内容处理** | 节点创建/压缩时 | 原文、目标字数（可选） | content, phrase, keywords |

### 6.2 语义切割任务

**职责**：
- 将长文本切分为语义完整的小段
- 进行代词消解（将"他/她/它"替换为明确指代对象）

**输入**：原始聊天记录文本

**输出要求**：
- segments: string[]，每个片段语义完整
- 每段长度建议不超过200字符
- 代词已消解，避免后续回忆时指代不明

### 6.3 内容处理任务

**职责**：
- 提取/生成短语摘要
- 提取关键词
- 如提供目标字数，压缩内容至目标长度

**输入**：
- text: string，原文
- targetLength?: number，目标字数（可选，未提供则保持原文）

**输出要求**：
- content: string，处理后的内容（如有目标字数则压缩）
- phrase: string，短语摘要（10-20字）
- keywords: string[]，关键词列表（3-5个，名词或名词短语）

### 6.4 重试策略

**失败定义**：
- 小模型服务不可用（网络错误、服务崩溃）
- 返回格式不符合预期（无法解析JSON）
- 返回内容明显错误（空内容、乱码）

**重试机制**：
- 最大重试次数：15次
- 退避策略：指数退避（1s, 2s, 4s, ...，上限30s）
- 最终失败处理：保留原内容，记录错误日志，继续后续流程

---

## 7. 部署与依赖

### 7.1 依赖安装

```bash
# 核心依赖
bun install levelgraph classic-level uuid

# 开发依赖
bun install -d @types/uuid
```

### 7.2 系统要求

| 项目 | 要求 |
|------|------|
| 运行时 | Bun ≥ 1.0 或 Node.js ≥ 18 |
| 内存 | 取决于记忆数据量和节点数上限 |
| 磁盘 | SSD推荐，存储需求 = 节点数 × 平均内容大小 |
| 操作系统 | Linux/macOS/Windows（LevelDB支持） |

### 7.3 小模型服务

小模型作为独立服务运行，记忆系统通过HTTP API调用：

- 支持本地部署（如Ollama）或远程API
- 建议模型：7B级别中文模型（如Qwen2.5:7b）
- 服务地址通过环境变量配置

---

## 8. 性能考量

### 8.1 存储性能

- LevelDB的LSM树结构适合写密集型场景（记忆创建）
- 读性能通过Hexastore六重索引保障
- 大数据量时考虑添加关键词倒排索引

### 8.2 压缩性能

- 压缩是资源密集型操作（小模型调用）
- 时间片机制防止压缩占用过多资源
- Worker线程隔离，不影响主流程响应

### 8.3 搜索性能

- BFS深度默认限制为2，控制查询范围
- 从关注点出发，而非全图遍历
- 关键词匹配可在数据库层过滤，减少数据传输

---

## 9. 扩展点

### 9.1 存储后端替换

如需替换LevelGraph：
- 实现NodeStore和LinkStore接口
- 保持RDF三元组语义或自定义存储模型
- 关注点：事务支持、图遍历性能、存储效率

### 9.2 压缩策略替换

- 当前基于重要性比例压缩
- 可扩展：基于语义的智能压缩（保留关键句）
- 可扩展：多层级压缩（先摘要比率，再压缩内容）

### 9.3 检索策略扩展

- 当前基于关键词匹配
- 可扩展：向量相似度检索（并行或替代）
- 可扩展：时间范围筛选

---

**最后更新**：2026-02-06
